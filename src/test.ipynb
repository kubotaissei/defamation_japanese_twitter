{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015756,
     "end_time": "2021-11-16T19:32:29.999526",
     "exception": false,
     "start_time": "2021-11-16T19:32:29.98377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.02543,
     "end_time": "2021-11-16T19:32:30.040766",
     "exception": false,
     "start_time": "2021-11-16T19:32:30.015336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    target_col='label'\n",
    "    num_workers=4\n",
    "    # ====================================================\n",
    "    # model\n",
    "    # ====================================================\n",
    "    model=\"studio-ousia/luke-japanese-large\"\n",
    "    mlm_dir='./drive/MyDrive/Colab Notebooks/hate-speech-detection/mlm/exp02/'\n",
    "    rnn='GRU' # [None, 'GRU', 'LSTM']\n",
    "    pooling='mean' #TO DO [\"mean\", \"max\", \"attention\"]\n",
    "    # ====================================================\n",
    "    # model tuning\n",
    "    # ====================================================\n",
    "    reinit_layers=-1 #TO DO\n",
    "    multi_sample_dropout=0.2\n",
    "    n_msd = 7 # 5~8\n",
    "    # ====================================================\n",
    "    # optimizer\n",
    "    # ====================================================\n",
    "    encoder_lr=1e-5\n",
    "    decoder_lr=1e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    weight_decay=0.2\n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    epochs=4\n",
    "    scheduler='cosine'\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    # ====================================================\n",
    "    # batch size\n",
    "    # ====================================================\n",
    "    train_batch_size=32\n",
    "    valid_batch_size=32\n",
    "    # ====================================================\n",
    "    # gradient\n",
    "    # ====================================================\n",
    "    max_grad_norm=1\n",
    "    gradient_accumulation_steps=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016162,
     "end_time": "2021-11-16T19:32:40.221507",
     "exception": false,
     "start_time": "2021-11-16T19:32:40.205345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 30.77583,
     "end_time": "2021-11-16T19:33:11.013554",
     "exception": false,
     "start_time": "2021-11-16T19:32:40.237724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.13.1\n",
      "transformers.__version__: 4.23.1\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01915,
     "end_time": "2021-11-16T19:33:11.052159",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.033009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, hiddendim_fc):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.num_hidden_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hiddendim_fc = hiddendim_fc\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        q_t = np.random.normal(loc=0.0, scale=0.1, size=(1, self.hidden_size))\n",
    "        self.q = nn.Parameter(torch.from_numpy(q_t)).float()\n",
    "        w_ht = np.random.normal(loc=0.0, scale=0.1, size=(self.hidden_size, self.hiddendim_fc))\n",
    "        self.w_h = nn.Parameter(torch.from_numpy(w_ht)).float()\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n",
    "                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n",
    "        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n",
    "        out = self.attention(hidden_states)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "    def attention(self, h):\n",
    "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
    "        v = F.softmax(v, -1)\n",
    "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
    "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.637101,
     "end_time": "2021-11-16T19:33:11.805349",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.168248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (5256, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80074aa43</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>まともに相手されてない人との関係なんて\\nそんな大事にするものか？</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6378fea6b</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>最近はアヘアヘQSマンやない？ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c535f5613</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e76638295</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51e4036bf</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       source                                               text  label\n",
       "0  80074aa43     news4vip                  まともに相手されてない人との関係なんて\\nそんな大事にするものか？      0\n",
       "1  6378fea6b  livejupiter              最近はアヘアヘQSマンやない？ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!      0\n",
       "2  c535f5613  livejupiter    日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな      1\n",
       "3  e76638295  livejupiter   よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで      0\n",
       "4  51e4036bf     newsplus  押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape: (3223, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001026808</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>上でも言ったけどオタクレベルの知識求めてる訳じゃない\\nただ囲碁やります！って人が誰1人プロ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00465ac96</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>たとえば、黒人なんかは、生物学的欠陥はないのに、文化的要因で、悪循環に陥り、実力をつけられず...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004674725</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>そうなんやろなあ色々と勿体ない感じしたわ\\n終わり方と黒幕キャラは好きやったで\\n\\nちなワ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00474460f</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>法的というか自治体ごとにバラバラの条例で定めてるだけだからな\\n普通の淫行条例だと「青少年に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004a7525c</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど、\\n現地は不測の事...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       source                                               text\n",
       "0  001026808     news4vip  上でも言ったけどオタクレベルの知識求めてる訳じゃない\\nただ囲碁やります！って人が誰1人プロ...\n",
       "1  00465ac96  livejupiter  たとえば、黒人なんかは、生物学的欠陥はないのに、文化的要因で、悪循環に陥り、実力をつけられず...\n",
       "2  004674725  livejupiter  そうなんやろなあ色々と勿体ない感じしたわ\\n終わり方と黒幕キャラは好きやったで\\n\\nちなワ...\n",
       "3  00474460f     news4vip  法的というか自治体ごとにバラバラの条例で定めてるだけだからな\\n普通の淫行条例だと「青少年に...\n",
       "4  004a7525c     newsplus  別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど、\\n現地は不測の事..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "def clean_text(text):\n",
    "    return text.replace(' ', '').replace('　', '').replace('__BR__', '\\n').replace('\\xa0', '').replace('\\r', '').lstrip('\\n')\n",
    "\n",
    "train['text'] = train['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "display(train.head())\n",
    "print(f\"test.shape: {test.shape}\")\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02099,
     "end_time": "2021-11-16T19:33:11.849001",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.828011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    1052\n",
       "1    1051\n",
       "2    1051\n",
       "3    1051\n",
       "4    1051\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_col].astype(int))):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02017,
     "end_time": "2021-11-16T19:33:11.963889",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.943719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 8.833709,
     "end_time": "2021-11-16T19:33:20.817889",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.98418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270ca6adb11944dc9f1ab9740fb5292a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 77\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Define max_len\n",
    "# ====================================================\n",
    "for text_col in ['text']:\n",
    "    train_lengths = []\n",
    "    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        train_lengths.append(length)\n",
    "\n",
    "CFG.max_len = max(train_lengths) + 3 # cls & sep & sep\n",
    "print(f\"max_len: {CFG.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.040128,
     "end_time": "2021-11-16T19:33:20.931029",
     "exception": false,
     "start_time": "2021-11-16T19:33:20.890901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df[cfg.target_col].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        encoding = self.cfg.tokenizer.encode_plus(\n",
    "            self.texts[item],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.cfg.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            text=self.texts[item],\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.tensor(self.labels[item]),\n",
    "        )\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        encoding = self.cfg.tokenizer.encode_plus(\n",
    "            self.texts[item],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.cfg.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            text=self.texts[item],\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02209,
     "end_time": "2021-11-16T19:33:20.978793",
     "exception": false,
     "start_time": "2021-11-16T19:33:20.956703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.032939,
     "end_time": "2021-11-16T19:33:21.034275",
     "exception": false,
     "start_time": "2021-11-16T19:33:21.001336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        if cfg.rnn == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                self.config.hidden_size,\n",
    "                self.config.hidden_size,\n",
    "                # bidirectional=True,\n",
    "                batch_first=True,\n",
    "            )\n",
    "        elif cfg.rnn == \"GRU\":\n",
    "            self.rnn = nn.GRU(\n",
    "                self.config.hidden_size,\n",
    "                self.config.hidden_size,\n",
    "                # bidirectional=True,\n",
    "                batch_first=True,\n",
    "            )\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(self.cfg.multi_sample_dropout) for _ in range(self.cfg.n_msd)])\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 2)\n",
    "        for layer in self.model.encoder.layer[self.cfg.reinit_layers:]:\n",
    "            for module in layer.modules():\n",
    "                self._init_weights(module)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        out, _ = self.rnn(outputs['last_hidden_state'], None)\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(out.size()).float()\n",
    "        if self.cfg.pooling == \"mean\":\n",
    "            sum_embeddings = torch.sum(out * input_mask_expanded, 1)\n",
    "            sum_mask = input_mask_expanded.sum(1)\n",
    "            sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "            sequence_output = sum_embeddings / sum_mask\n",
    "        elif self.cfg.pooling == \"max\":\n",
    "            out[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
    "            sequence_output = torch.max(out, 1)[0]\n",
    "        elif self.cfg.pooling == \"attention\":\n",
    "            pass\n",
    "        else:\n",
    "            sequence_output = out[:,-1,:]\n",
    "        output = sum([self.fc(dropout(sequence_output)) for dropout in self.dropouts])/self.cfg.n_msd\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    DataFrameからモデリング時に使用するDataModuleを作成\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, train_df, fold):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.fold = fold\n",
    "        self.train_df = train_df\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_folds = self.train_df[self.train_df['fold'] != self.fold].reset_index(drop=True)\n",
    "        self.valid_folds = self.train_df[self.train_df['fold'] == self.fold].reset_index(drop=True)\n",
    "        self.cfg.num_train_steps = int(len(self.train_folds) / self.cfg.train_batch_size * self.cfg.epochs)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(TrainDataset(self.cfg, self.train_folds),\n",
    "                        batch_size=self.cfg.train_batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=self.cfg.num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(TrainDataset(self.cfg, self.valid_folds),\n",
    "                        batch_size=self.cfg.valid_batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=self.cfg.num_workers, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = CustomDataModule(CFG,train,3)\n",
    "datamodule.setup()\n",
    "features = list(datamodule.train_dataloader())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(CFG.model, output_hidden_states=True)\n",
    "model = AutoModel.from_pretrained(CFG.model, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(config.hidden_size, config.hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(features['input_ids'], features['attention_mask'])\n",
    "    rnn_out, _ = lstm(outputs['last_hidden_state'], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 77, 1024])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 32, 77, 1024])\n",
      "torch.Size([32, 77, 1024])\n"
     ]
    }
   ],
   "source": [
    "all_hidden_states = torch.stack(outputs['hidden_states'])\n",
    "last_hidden_state = outputs['last_hidden_state']\n",
    "print(all_hidden_states.shape)\n",
    "print(last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mセル25 を /home/workspace/labo/hatespeech_detection/src/test.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b75626f7461222c2273657474696e6773223a7b22686f7374223a227373683a2f2f696e75227d7d/home/workspace/labo/hatespeech_detection/src/test.ipynb#Y122sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m all_hidden_states\u001b[39m.\u001b[39;49mappend()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "all_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 32, 77, 1024])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([all_hidden_states, rnn_out.unsqueeze(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddendim_fc = 128\n",
    "pooler = AttentionPooling(config.num_hidden_layers+1, config.hidden_size, hiddendim_fc)\n",
    "attention_pooling_embeddings = pooler(torch.cat([all_hidden_states, rnn_out.unsqueeze(0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_pooling_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
