{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015756,
     "end_time": "2021-11-16T19:32:29.999526",
     "exception": false,
     "start_time": "2021-11-16T19:32:29.98377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.02543,
     "end_time": "2021-11-16T19:32:30.040766",
     "exception": false,
     "start_time": "2021-11-16T19:32:30.015336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ====================================================\n",
    "    # general\n",
    "    # ====================================================\n",
    "    seed = 42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1]\n",
    "    train=True\n",
    "    train_csv = '../input/train.csv'\n",
    "    test_csv = '../input/test.csv'\n",
    "    target_col='label'\n",
    "    output_dir = '../output/'\n",
    "    num_workers=4\n",
    "    # ====================================================\n",
    "    # model\n",
    "    # ====================================================\n",
    "    model=\"studio-ousia/luke-japanese-large\"\n",
    "    # mlm_dir='./drive/MyDrive/Colab Notebooks/hate-speech-detection/mlm/exp02/'\n",
    "    rnn='GRU' # [None, 'GRU', 'LSTM']\n",
    "    pooling='max_old' #[\"None\", \"mean\", \"max\", \"attention\"] # RANDOM SAMPLING\n",
    "    # ====================================================\n",
    "    # model tuning\n",
    "    # ====================================================\n",
    "    reinit_layers=-1\n",
    "    multi_sample_dropout=0.2\n",
    "    n_msd = 7 # 5~8\n",
    "    # ====================================================\n",
    "    # optimizer\n",
    "    # ====================================================\n",
    "    encoder_lr=1e-5\n",
    "    decoder_lr=1e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    weight_decay=0.2\n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    epochs=1\n",
    "    scheduler='cosine'\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    # ====================================================\n",
    "    # batch size\n",
    "    # ====================================================\n",
    "    train_batch_size=16\n",
    "    valid_batch_size=16\n",
    "    # ====================================================\n",
    "    # gradient\n",
    "    # ====================================================\n",
    "    max_grad_norm=1\n",
    "    gradient_accumulation_steps=1\n",
    "    \n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "cfg_dict = class2dict(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5][-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016162,
     "end_time": "2021-11-16T19:32:40.221507",
     "exception": false,
     "start_time": "2021-11-16T19:32:40.205345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 30.77583,
     "end_time": "2021-11-16T19:33:11.013554",
     "exception": false,
     "start_time": "2021-11-16T19:32:40.237724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.13.1\n",
      "transformers.__version__: 4.23.1\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger, WandbLogger\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018406,
     "end_time": "2021-11-16T19:33:11.150174",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.131768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.637101,
     "end_time": "2021-11-16T19:33:11.805349",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.168248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (5256, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80074aa43</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>まともに相手されてない人との関係なんて\\nそんな大事にするものか？</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6378fea6b</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>最近はアヘアヘQSマンやない？ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c535f5613</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e76638295</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51e4036bf</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       source                                               text  label\n",
       "0  80074aa43     news4vip                  まともに相手されてない人との関係なんて\\nそんな大事にするものか？      0\n",
       "1  6378fea6b  livejupiter              最近はアヘアヘQSマンやない？ｲｲ!(・∀・)+1-0(・Ａ・)ｲｸﾅｲ!      0\n",
       "2  c535f5613  livejupiter    日本人として生まれても無能な低学歴って分かったら日本人の権利剥奪して追放すべきやろ\\n甘えるな      1\n",
       "3  e76638295  livejupiter   よくよく思えば川上は配布にしたらとんでもなく有能だよな\\nガチャから引いたら圧倒的歓喜レベルやで      0\n",
       "4  51e4036bf     newsplus  押井は原作レイプの専門家だから\\n原作マンガの真意を誤解させることに関してはプロだが\\nそれ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape: (3223, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001026808</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>上でも言ったけどオタクレベルの知識求めてる訳じゃない\\nただ囲碁やります！って人が誰1人プロ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00465ac96</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>たとえば、黒人なんかは、生物学的欠陥はないのに、文化的要因で、悪循環に陥り、実力をつけられず...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004674725</td>\n",
       "      <td>livejupiter</td>\n",
       "      <td>そうなんやろなあ色々と勿体ない感じしたわ\\n終わり方と黒幕キャラは好きやったで\\n\\nちなワ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00474460f</td>\n",
       "      <td>news4vip</td>\n",
       "      <td>法的というか自治体ごとにバラバラの条例で定めてるだけだからな\\n普通の淫行条例だと「青少年に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004a7525c</td>\n",
       "      <td>newsplus</td>\n",
       "      <td>別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど、\\n現地は不測の事...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       source                                               text\n",
       "0  001026808     news4vip  上でも言ったけどオタクレベルの知識求めてる訳じゃない\\nただ囲碁やります！って人が誰1人プロ...\n",
       "1  00465ac96  livejupiter  たとえば、黒人なんかは、生物学的欠陥はないのに、文化的要因で、悪循環に陥り、実力をつけられず...\n",
       "2  004674725  livejupiter  そうなんやろなあ色々と勿体ない感じしたわ\\n終わり方と黒幕キャラは好きやったで\\n\\nちなワ...\n",
       "3  00474460f     news4vip  法的というか自治体ごとにバラバラの条例で定めてるだけだからな\\n普通の淫行条例だと「青少年に...\n",
       "4  004a7525c     newsplus  別のジャーナリストの感想として言われてるので客観的な事実とは言えないけど、\\n現地は不測の事..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv(CFG.train_csv)\n",
    "test = pd.read_csv(CFG.test_csv)\n",
    "def clean_text(text):\n",
    "    return text.replace(' ', '').replace('　', '').replace('__BR__', '\\n').replace('\\xa0', '').replace('\\r', '').lstrip('\\n')\n",
    "\n",
    "train['text'] = train['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "display(train.head())\n",
    "print(f\"test.shape: {test.shape}\")\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02099,
     "end_time": "2021-11-16T19:33:11.849001",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.828011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    1052\n",
       "1    1051\n",
       "2    1051\n",
       "3    1051\n",
       "4    1051\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_col].astype(int))):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02017,
     "end_time": "2021-11-16T19:33:11.963889",
     "exception": false,
     "start_time": "2021-11-16T19:33:11.943719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e4b624cabc48c18dfb9e4b66ab6d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 77\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Define max_len\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "for text_col in ['text']:\n",
    "    train_lengths = []\n",
    "    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        train_lengths.append(length)\n",
    "\n",
    "CFG.max_len = max(train_lengths) + 3 # cls & sep & sep\n",
    "print(f\"max_len: {CFG.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.040128,
     "end_time": "2021-11-16T19:33:20.931029",
     "exception": false,
     "start_time": "2021-11-16T19:33:20.890901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df[\"text\"].values\n",
    "        self.labels = df[cfg.target_col].values\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(cfg.model)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.texts[item],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.cfg.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            text=self.texts[item],\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.tensor(self.labels[item]),\n",
    "        )\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df[\"text\"].values\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(cfg.model)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.texts[item],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.cfg.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            text=self.texts[item],\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02209,
     "end_time": "2021-11-16T19:33:20.978793",
     "exception": false,
     "start_time": "2021-11-16T19:33:20.956703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.032939,
     "end_time": "2021-11-16T19:33:21.034275",
     "exception": false,
     "start_time": "2021-11-16T19:33:21.001336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, hiddendim_fc):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.num_hidden_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hiddendim_fc = hiddendim_fc\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        q_t = np.random.normal(loc=0.0, scale=0.1, size=(1, self.hidden_size))\n",
    "        self.q = nn.Parameter(torch.from_numpy(q_t)).float()\n",
    "        w_ht = np.random.normal(loc=0.0, scale=0.1, size=(self.hidden_size, self.hiddendim_fc))\n",
    "        self.w_h = nn.Parameter(torch.from_numpy(w_ht)).float()\n",
    "\n",
    "    def forward(self, all_hidden_states):\n",
    "        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n",
    "                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n",
    "        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n",
    "        out = self.attention(hidden_states)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "    def attention(self, h):\n",
    "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
    "        v = F.softmax(v, -1)\n",
    "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
    "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
    "        return v\n",
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        if cfg.rnn == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                self.config.hidden_size,\n",
    "                self.config.hidden_size,\n",
    "                # bidirectional=True,\n",
    "                batch_first=True,\n",
    "            )\n",
    "        elif cfg.rnn == \"GRU\":\n",
    "            self.rnn = nn.GRU(\n",
    "                self.config.hidden_size,\n",
    "                self.config.hidden_size,\n",
    "                # bidirectional=True,\n",
    "                batch_first=True,\n",
    "            )\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(self.cfg.multi_sample_dropout) for _ in range(self.cfg.n_msd)])\n",
    "        self.pooler = AttentionPooling(self.config.num_hidden_layers+1, self.config.hidden_size, 128)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 2)\n",
    "        for layer in self.model.encoder.layer[self.cfg.reinit_layers:]:\n",
    "            for module in layer.modules():\n",
    "                self._init_weights(module)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        all_hidden_states = torch.stack(outputs['hidden_states'])\n",
    "        rnn_out, _ = self.rnn(outputs['last_hidden_state'], None)\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(rnn_out.size()).float()\n",
    "        if self.cfg.pooling == \"mean_old\":\n",
    "            sequence_output = rnn_out.mean(axis=1)\n",
    "        elif self.cfg.pooling == \"max_old\":\n",
    "            sequence_output, _ = rnn_out.max(1)\n",
    "        elif self.cfg.pooling == \"mean\":\n",
    "            sum_embeddings = torch.sum(rnn_out * input_mask_expanded, 1)\n",
    "            sum_mask = input_mask_expanded.sum(1)\n",
    "            sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "            sequence_output = sum_embeddings / sum_mask\n",
    "        elif self.cfg.pooling == \"max\":\n",
    "            rnn_out[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
    "            sequence_output = torch.max(rnn_out, 1)[0]\n",
    "        elif self.cfg.pooling == \"attention\":\n",
    "            torch.cat([all_hidden_states, rnn_out.unsqueeze(0)])\n",
    "            sequence_output = self.pooler(torch.cat([all_hidden_states, rnn_out.unsqueeze(0)]))\n",
    "        else:\n",
    "            sequence_output = rnn_out[:,-1,:]\n",
    "        output = sum([self.fc(dropout(sequence_output)) for dropout in self.dropouts])/self.cfg.n_msd\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    DataFrameからモデリング時に使用するDataModuleを作成\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, train_df, fold):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.fold = fold\n",
    "        self.train_df = train_df\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_folds = self.train_df[self.train_df['fold'] != self.fold].reset_index(drop=True)\n",
    "        self.valid_folds = self.train_df[self.train_df['fold'] == self.fold].reset_index(drop=True)\n",
    "        self.cfg.num_train_steps = int(len(self.train_folds) / self.cfg.train_batch_size * self.cfg.epochs)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(TrainDataset(self.cfg, self.train_folds),\n",
    "                        batch_size=self.cfg.train_batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=self.cfg.num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(TrainDataset(self.cfg, self.valid_folds),\n",
    "                        batch_size=self.cfg.valid_batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=self.cfg.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "class CustomLitModule(pl.LightningModule):\n",
    "    def __init__(self, cfg, fold):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = CustomModel(cfg, config_path=None, pretrained=True)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.cfg = cfg\n",
    "        self.fold = fold\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        logits = self.model(input_ids, attention_mask)\n",
    "        loss = 0 if labels is None else self.criterion(logits, labels)\n",
    "        return loss, logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, preds = self.forward(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"],\n",
    "        )\n",
    "        \n",
    "        sch = self.lr_schedulers()\n",
    "        if self.cfg.batch_scheduler:\n",
    "            sch.step()\n",
    "        return {\"loss\": loss, \"batch_preds\": preds, \"batch_labels\": batch[\"labels\"]}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, preds = self.forward(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"],\n",
    "        )\n",
    "        return {\"loss\": loss, \"batch_preds\": preds, \"batch_labels\": batch[\"labels\"]}\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        loss, preds = self.forward(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "        )\n",
    "        return preds\n",
    "\n",
    "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
    "        # loss計算\n",
    "        epoch_preds = torch.cat([x[\"batch_preds\"] for x in outputs])\n",
    "        epoch_labels = torch.cat([x[\"batch_labels\"] for x in outputs])\n",
    "        epoch_loss = self.criterion(epoch_preds, epoch_labels)\n",
    "        self.log(f\"[fold{self.fold}]{mode}_loss\", epoch_loss, logger=True, prog_bar=True)\n",
    "        self.log(f\"[fold{self.fold}]{mode}_f1\", f1_score(epoch_labels.cpu(), epoch_preds.cpu().argmax(dim=1)), logger=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "            param_optimizer = list(model.named_parameters())\n",
    "            no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "            optimizer_parameters = [\n",
    "                {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "                {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "                {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "                'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "            ]\n",
    "            return optimizer_parameters\n",
    "\n",
    "        optimizer_parameters = get_optimizer_params(self.model,\n",
    "                                                    encoder_lr=self.cfg.encoder_lr, \n",
    "                                                    decoder_lr=self.cfg.decoder_lr,\n",
    "                                                    weight_decay=self.cfg.weight_decay)\n",
    "        optimizer = AdamW(optimizer_parameters, lr=self.cfg.encoder_lr, eps=self.cfg.eps, betas=self.cfg.betas)\n",
    "        # ====================================================\n",
    "        # scheduler\n",
    "        # ====================================================\n",
    "        def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "            if cfg.scheduler=='linear':\n",
    "                scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "                )\n",
    "            elif cfg.scheduler=='cosine':\n",
    "                scheduler = get_cosine_schedule_with_warmup(\n",
    "                    optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "                )\n",
    "            return scheduler\n",
    "\n",
    "        scheduler = {\n",
    "                \"scheduler\": get_scheduler(self.cfg, optimizer, self.cfg.num_train_steps),\n",
    "                \"interval\": \"step\" if self.cfg.batch_scheduler else \"epoch\",\n",
    "            }\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../output/studio-ousia/luke-japanese-large/GRU/max_old/wandb/run-20221222_213327-1nx1imya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kubotaissei/hatespeech_detection/runs/1nx1imya\" target=\"_blank\">studio-ousia/luke-japanese-large_GRU_max_old</a></strong> to <a href=\"https://wandb.ai/kubotaissei/hatespeech_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Some weights of the model checkpoint at studio-ousia/luke-japanese-large were not used when initializing LukeModel: ['lm_head.dense.bias', 'entity_predictions.transform.LayerNorm.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'entity_predictions.transform.dense.bias', 'entity_predictions.transform.dense.weight', 'entity_predictions.bias', 'entity_predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing LukeModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | CustomModel      | 566 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "566 M     Trainable params\n",
      "0         Non-trainable params\n",
      "566 M     Total params\n",
      "2,264.634 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcd323d060d4af2bb9f6441a908d81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fb2d2d08464ac2ab74cc1981d4017a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d237fe92c4174c898879a8cf2ca0bae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 52: '[fold0]val_f1' reached 0.00000 (best 0.00000), saving model to '/home/workspace/labo/hatespeech_detection/output/studio-ousia/luke-japanese-large/GRU/max_old/fold_0-v5.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9a52233bfc42148fc0cc9a1cd69857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      [fold0]val_f1                 0.0\n",
      "     [fold0]val_loss        0.23703131079673767\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at studio-ousia/luke-japanese-large were not used when initializing LukeModel: ['lm_head.dense.bias', 'entity_predictions.transform.LayerNorm.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'entity_predictions.transform.dense.bias', 'entity_predictions.transform.dense.weight', 'entity_predictions.bias', 'entity_predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing LukeModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603f0120cf864b21836348cc02d75a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 52it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id\n",
       "label      \n",
       "0      3223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Some weights of the model checkpoint at studio-ousia/luke-japanese-large were not used when initializing LukeModel: ['lm_head.dense.bias', 'entity_predictions.transform.LayerNorm.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'entity_predictions.transform.dense.bias', 'entity_predictions.transform.dense.weight', 'entity_predictions.bias', 'entity_predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing LukeModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | CustomModel      | 566 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "566 M     Trainable params\n",
      "0         Non-trainable params\n",
      "566 M     Total params\n",
      "2,264.634 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0204035b5e0542cdb0fa5aeb5f7e6919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbfe190a509464cb1f7dc16ef874151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cdd23620dc4f1cbbedb388c3aa4ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 52: '[fold1]val_f1' reached 0.00000 (best 0.00000), saving model to '/home/workspace/labo/hatespeech_detection/output/studio-ousia/luke-japanese-large/GRU/max_old/fold_1-v3.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdbb4b38878484d89197d040b576e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      [fold1]val_f1                 0.0\n",
      "     [fold1]val_loss        0.17478825151920319\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at studio-ousia/luke-japanese-large were not used when initializing LukeModel: ['lm_head.dense.bias', 'entity_predictions.transform.LayerNorm.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'entity_predictions.transform.dense.bias', 'entity_predictions.transform.dense.weight', 'entity_predictions.bias', 'entity_predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing LukeModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LukeModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bceefdb196b4f4aae87ea51ee8f9a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 52it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id\n",
       "label      \n",
       "0      3221\n",
       "1         2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[fold0]val_loss</th>\n",
       "      <th>[fold0]val_f1</th>\n",
       "      <th>[fold1]val_loss</th>\n",
       "      <th>[fold1]val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.237031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.174788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   [fold0]val_loss  [fold0]val_f1  [fold1]val_loss  [fold1]val_f1\n",
       "0         0.237031            0.0              NaN            NaN\n",
       "1              NaN            NaN         0.174788            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id\n",
       "label      \n",
       "0      3223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.seed_everything(CFG.seed)\n",
    "preds = []\n",
    "results = []\n",
    "test_dataloader = DataLoader(TestDataset(CFG, test),\n",
    "                        batch_size=32,\n",
    "                        shuffle=False,\n",
    "                        num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "out_dir = Path(CFG.output_dir)/CFG.model/CFG.rnn/CFG.pooling\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "wandb_logger = WandbLogger(\n",
    "    name=f\"{CFG.model}_{CFG.rnn}_{CFG.pooling}\",\n",
    "    save_dir=str(out_dir),\n",
    "    project=\"hatespeech_detection\",\n",
    "    group=CFG.model,\n",
    "    anonymous=True,\n",
    ")\n",
    "for k, v in cfg_dict.items():\n",
    "    wandb_logger.experiment.config[k] = v\n",
    "for fold in CFG.trn_fold:\n",
    "    logger = CSVLogger(save_dir=out_dir, name=f\"fold_{fold}\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=out_dir,\n",
    "        filename=f\"fold_{fold}\",\n",
    "        verbose=True,\n",
    "        save_top_k=1,\n",
    "        monitor=f\"[fold{fold}]val_f1\",\n",
    "        mode=\"max\",\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=CFG.epochs,\n",
    "        accelerator=\"gpu\",\n",
    "        # strategy=\"dp\",\n",
    "        devices=1,\n",
    "        gradient_clip_val=CFG.max_grad_norm,\n",
    "        gradient_clip_algorithm=\"value\",\n",
    "        amp_backend=\"native\",\n",
    "        deterministic=True,\n",
    "        auto_select_gpus=False,\n",
    "        benchmark=False,\n",
    "        default_root_dir=os.getcwd(),\n",
    "        limit_train_batches=0.2,\n",
    "        limit_val_batches=0.2,\n",
    "        accumulate_grad_batches=CFG.gradient_accumulation_steps,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        logger=[wandb_logger,logger],\n",
    "    )\n",
    "    datamodule = CustomDataModule(CFG, train, fold)\n",
    "    model = CustomLitModule(CFG, fold)\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    results += trainer.validate(model=model, dataloaders=datamodule.val_dataloader())\n",
    "    logits = trainer.predict(model=CustomLitModule(CFG, fold), dataloaders=test_dataloader)\n",
    "    pred = torch.cat(logits)\n",
    "    test[\"label\"] = pred.argmax(1)\n",
    "    test[[\"id\", \"label\"]].to_csv(out_dir/f\"submission_fold{fold}.csv\", index=None)\n",
    "    display(test[[\"id\", \"label\"]].groupby(\"label\").count())\n",
    "    preds.append(pred)\n",
    "    del trainer, datamodule, model; gc.collect()\n",
    "\n",
    "wandb_logger.finalize(\"success\")\n",
    "result_df = pd.DataFrame([{k[7:]: v for k,v in result.items()} for result in results])\n",
    "display(result_df)\n",
    "test[\"label\"] = (sum(preds) / len(preds)).argmax(1)\n",
    "test[[\"id\", \"label\"]].to_csv(out_dir/\"submission_ave.csv\", index=None)\n",
    "display(test[[\"id\", \"label\"]].groupby(\"label\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame([{k[7:]: v for k,v in result.items()} for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[\"val_f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id\n",
       "label      \n",
       "0      3223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[\"label\"] = sum(preds[0:4]).argmax(1)\n",
    "test[[\"id\", \"label\"]].to_csv(out_dir/\"submission_04.csv\", index=None)\n",
    "display(test[[\"id\", \"label\"]].groupby(\"label\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id\n",
       "label      \n",
       "0      3223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[\"label\"] = sum(preds[0:3]).argmax(1)\n",
    "test[[\"id\", \"label\"]].to_csv(out_dir/\"submission_03.csv\", index=None)\n",
    "display(test[[\"id\", \"label\"]].groupby(\"label\").count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do\n",
    "- Wandbが保存されない問題を解決(Foldごとにスクリプトを分割する)\n",
    "- Hydraを用いたtrainの書き方に変更する(ハイパラ探索のため)\n",
    "- いろいろ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:15:33) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
